{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Overview\n",
        "I will be working on prompting large language models (LLMs) such as ChatGPT. Language model prompting is the process of providing a model with an input text and then having the model generate a response as output. Prompting can be used to complete breadth of tasks such as summarization (e.g., “Summarize the following paragraph: <paragraph written out here> Summary:”) or extraction (e.g., “Extract the phone number from the user bio: <bio written out here>.”).\n",
        "\n",
        "The task I am trying to solve here is text rewriting. Specifically, the goal is to rewrite GoFundMe fundraising pitches to different emotions (e.g., sad). There is no off-the-shelf solution. Most studies in the rewriting tasks focus on a particular transformation type within the boundaries of single sentences. However, a fundraising pitch contains 170 words on average (calculated based on pitches in the medical category: https://www.gofundme.com/discover/medical-fundraiser) and each one is a coherent story. We will explore and develop prompts and fine-tuning strategies to enable LLMs to better rewrite GoFundMe fundraising pitches to different emotions.\n",
        "\n",
        "The code consists of two parts:\n",
        "\n",
        "1.   Explore prompt engineering: zero-shot, few-shot, and chain-of-thought\n",
        "2.   Explore strategies for LLM fine-tuning\n"
      ],
      "metadata": {
        "id": "YI316SNDAss-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Task, Data, and Setup\n"
      ],
      "metadata": {
        "id": "IQdfglT0BAfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task\n",
        "Rewrite GoFundMe fundraising pitches to different emotions. We work with the following eight types of emotions: “fear, love, sadness, surprise, optimism, gratitude, anger, joy”\n"
      ],
      "metadata": {
        "id": "Zwn2BsYzBGb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data\n",
        "\n",
        "I worked on 2 datasets:\n",
        "1.   Development set. We provide you with eight random stories from GoFundMe.\n",
        "2.   A sample of 800 stories from GoFundMe that are associated with the eight emotions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C65BLz92BH5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "Mp2f-Zc5BUxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install dependencies"
      ],
      "metadata": {
        "id": "ZQco85yEBezt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install openai"
      ],
      "metadata": {
        "id": "EHXtGSNyBtTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513f44d9-ccd9-4b88-8f48-8036ddf257c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.23.6-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import necessary libraries, define helper function, and data"
      ],
      "metadata": {
        "id": "1LjiscaxBx8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Please use your own when running the code.\n",
        "\n",
        "client = OpenAI(\n",
        "    # api_key =\n",
        ")"
      ],
      "metadata": {
        "id": "2Ju3_EJHDU4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used OpenAI's gpt-3.5-turbo model and the chat completions endpoint in this example.\n",
        "\n",
        "This helper function will make it easier to use prompts and look at the generated outputs:"
      ],
      "metadata": {
        "id": "y56az7Z7CGYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_version = \"gpt-3.5-turbo\" # GPT-3.5\n",
        "\n",
        "def get_completion(prompt, model=model_version):\n",
        "  completion = client.chat.completions.create(\n",
        "      model = model_version,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      temperature=0, # this is the degree of randomness of the model's output\n",
        "  )\n",
        "  return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "ZuTve1mTCIhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I: Prompt Development\n",
        "\n",
        "In Part I, developed and improved upon prompts to rewrite GoFundMe fundraising pitches to different emotions, using the development set.\n",
        "\n",
        "The deliverables include:\n",
        "1.    Process. A description of different prompting strategies/prompts you tried in arriving at your final prompts.\n",
        "2.    Prompts. You should propose at least 3 prompts.\n",
        "3.    Results. For each prompt, report the rewritten text of the stories in the development set and your ratings of the rewritten text on a scale from 1 to 5, where 1 means not good and 5 means good. We ask you to privide three ratings: 1) instruction success: whether the rewrite accurately follows the instruction and conveys the target emotion that you asked for; 2) content preservation: wehther the content of the story (e.g., events, figures, topics) is preserved in the rewrite, independent of the emotion conveyed in the story ; 3) overall rating, considering both 1) and 2) and many other factors that you consider important for text rewrite task. See “Other things to consider” under “Useful resources”.\n",
        "\n",
        "4.    Error analysis. Analyze the trends you observe from the results of all the prompts. For example, why do some prompts work better than others? What are some common problems that exist in the prompts?  Do some prompts do better on a specific case than others? Finally, what did you learn from this prompting engineering exercise?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QDTrDzLXMX_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Useful resources\n",
        "\n",
        "1.   Prompting strategies: zero-shot, few-shots, chain-of-thought, and others (https://platform.openai.com/docs/guides/prompt-engineering, https://www.promptingguide.ai/)\n",
        "2.   Other things to consider\n",
        "  *   Text complexity\n",
        "  *   Length\n",
        "  *   Content preservation: whether the rewritten text preserves the essential content and meaning of the source text\n",
        "  *   Factuality: The rewrite only provides as much information as is present in the reference, without adding anything. It is not misleading and does not make any false statements.\n",
        "  *   Coherence: The rewrite is easy to understand, non-ambiguous, and logically coherent.\n",
        "  *   Fluency: Examines the clarity, grammar, and style of the written answer.\n",
        "3.    Examples and related papers\n",
        "  *   Figure 7 – Figure 19 in the appendix of paper [3]\n",
        "  *   Paper [4]\n"
      ],
      "metadata": {
        "id": "l4tS9cBpDtjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot"
      ],
      "metadata": {
        "id": "zWPI1mOM9Z-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = \"anger\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "\n",
        "You are a fundraising copywriter, hired to help edit a fundraising text\n",
        "which is delimited by triple backticks.\n",
        "Please write a new version of the text that conveys the emotion {emotion}\n",
        "Keep the new version's total wordcount within 90% to 110% of the original\n",
        "wordcount.\n",
        "\n",
        "Text: ```Hi, my name is Debbi and IÃ¢Â€Â™m fundraising for my brother Donald Webb.\n",
        "The sad news is that he is only 51 years old, and in 2016 he suffered a series of strokes that resulted in loss of motor skills and memory loss.\n",
        "Recently he was sent to the hospital because his kidneys are failing and is heading toward dialysis.\n",
        "This is in addition to other failing health factors including high blood pressure and diabetes.\n",
        "He needs to stay in the hospital for an extend amount of time.\n",
        "Each day he is in the hospital costs $450 to hold his bed at The Regency at Shelby in Shelby Township Mi, his care facility.\n",
        "Any help given would make sure he is cared for.```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccmBcoCU84vj",
        "outputId": "4879c449-8494-481e-c4f6-8cbd9ed14da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```Listen up! My name is Debbi and I'm here to raise funds for my brother Donald Webb. \n",
            "Let me tell you something that will make your blood boil - he's only 51 years old and back in 2016, he was hit with a barrage of strokes that robbed him of his motor skills and memories. \n",
            "And if that wasn't enough, now his kidneys are failing and he's on the fast track to dialysis. \n",
            "As if that's not infuriating already, he's also battling high blood pressure and diabetes. \n",
            "He's stuck in the hospital for who knows how long, and every single day there costs a whopping $450 just to keep his bed at The Regency at Shelby in Shelby Township Mi, his care facility. \n",
            "We need all the help we can get to ensure he gets the care he deserves.```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = \"love\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "\n",
        "You are a fundraising copywriter, hired to help edit a fundraising text\n",
        "which is delimited by triple backticks.\n",
        "Please write a new version of the text that conveys the emotion {emotion}\n",
        "Keep the new version's total wordcount within 90% to 110% of the original\n",
        "wordcount.\n",
        "Text: ```Well, another seizure decided to sneak up on me and hit me with its best shot! Again, I do not have any recollection of this incident.\n",
        "I was told that I was blue when they found me, gray and arm was cold as I lay on the gurney! I had to be resuscitated twice and a 3rd time in the ICU! My brain had swelling so I had to be iced up like a keg cooler! They didn't know if I was going to come out of it, and if I did, what kind of condition would I be in? Brain dead? Vegetable? Could understand but mobility all screwed up? I scared the hell put of my poor family who drove in from everywhere to be by my side until I got through this! They are absolutely amazing and I have to give a HUGE shout out to the fucking rock of our family, the most selfish, positive, unbelievably head strong woman to walk this 3rd rock.... MOM! You never get enough thanks! We'd all be lost without you and that's no joke!```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLcBFwiC-YNW",
        "outputId": "d6643a36-652f-4170-e4cf-dd612160f79a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```Love enveloped me in its warm embrace as another seizure tried to take me down. In the midst of darkness, I was surrounded by the unwavering love of my family. Their presence, their strength, their unwavering support carried me through the toughest of times. My mother, the rock of our family, stood by my side, her love shining brighter than any fear or doubt. Her selflessness, her positivity, her resilience, all a testament to the power of a mother's love. I am forever grateful for her, for without her, I would be lost in a sea of uncertainty. Thank you, Mom, for being my guiding light, my source of love and strength.```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = \"fear\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "\n",
        "You are a fundraising copywriter, hired to help edit a fundraising text\n",
        "which is delimited by triple backticks.\n",
        "Please write a new version of the text that conveys the emotion {emotion}\n",
        "Keep the new version's total wordcount within 90% to 110% of the original\n",
        "wordcount.\n",
        "Text: ```Unexpectedly on Friday my blood pressure skyrocketed.\n",
        "Causing me to have to go to the er.\n",
        "Once there, I was transferred to Dallas and diagnosed with severe preeclampsia. I am told I will be here until Greyson is born, which could be now to 34 weeks.\n",
        "Not only will he be premature , he has a heart defect that will most likely require surgery to correct.\n",
        "This was entirely unexpected. We have 3 other kiddos at home who still have needs and bills to be paid on top of the expenses that come with being in the hospital.\n",
        "Joseph has to eat and go back and forth between Dallas and Tyler. Any help is greatly appreciated as we navigate through these new challenges.```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)\n",
        "\n",
        "\"\"\"\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "M1sVYM4t-Yjg",
        "outputId": "f89bff40-5abe-419c-88cd-6411ddb72841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```Out of nowhere, my blood pressure surged on Friday, sending me rushing to the ER. \n",
            "After being transferred to Dallas, I received a terrifying diagnosis of severe preeclampsia. \n",
            "I'm facing a long stay until Greyson arrives, possibly as early as 34 weeks. \n",
            "Not only will he be born prematurely, but he also has a heart defect requiring surgery. \n",
            "This unexpected turn has left us reeling, with 3 kids at home needing care and bills piling up. \n",
            "Joseph is juggling meals and trips between Dallas and Tyler. \n",
            "Any support during this frightening time would mean the world to us as we confront these daunting challenges.```\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain-Thought"
      ],
      "metadata": {
        "id": "U3uFmj2H9dKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = \"love\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "System: You are an expert in emotional psychology and you can accurately write\n",
        "stories with different emotions.\n",
        "Text: ```Hi there. I hate that I'm even considering this, but at this point I probably have no pride anymore (sadly) so why not. Even if only $5 is raised that's $5 more towards these bills than I had! As most of you know, I've had some pretty big mystery medical issues going on for about 20 months or so now. With that has come all sorts of tests, procedures, medications, etc. While I have pretty decent health insurance, the bills for what I owe after insurance are starting to roll in more & more. I truly hate to beg for help, but honestly, I figured at this point what's it going to hurt if I do. Y'all have already formed your opinions of me, positive or negative, so why not?!```\n",
        "Tasks and Steps: The above is a story from GoFundMe. Your task is to write a new\n",
        "version of the text that conveys the emotion {emotion}. You need to follow the\n",
        "steps below. Let's think step by step.\n",
        "Step 1: Describe the content and main events of the story.\n",
        "Step 2: Think about what emotions conveyed in the current story.\n",
        "Step 3: Think about how you rewrite the same story but convey emotion {emotion}\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Akz_3R9gOE",
        "outputId": "2bcdf58c-b20d-48f5-cc62-bcb95879c17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: The story is about someone who is struggling with medical bills due to ongoing health issues. They are reaching out for help on a fundraising platform.\n",
            "\n",
            "Step 2: The current story conveys emotions of sadness, desperation, and a sense of defeat. The person feels like they have lost their pride and are reluctantly asking for help.\n",
            "\n",
            "Step 3: Rewrite the story to convey the emotion of love:\n",
            "\n",
            "\"Hello everyone. I am overwhelmed with gratitude for the love and support I have received during this challenging time. For the past 20 months, I have been facing mysterious medical issues that have led to numerous tests, procedures, and medications. While my health insurance has been helpful, the bills are starting to add up. I am humbly reaching out to ask for your help, not out of desperation, but out of love and appreciation for the community that surrounds me. Your generosity, no matter how big or small, will mean the world to me. Thank you for being a beacon of love and light in my life.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = \"sadness\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "System: You are an expert in emotional psychology and you can accurately write\n",
        "stories with different emotions.\n",
        "\n",
        "Text: ```hi everyone, iÃ¢Â€Â™m writing to raise awareness and funds to cremate my dad.\n",
        "My dad is currently on his death bed, he has a few days left.\n",
        "itÃ¢Â€Â™s only my mom thatÃ¢Â€Â™s working to take care of me and my 2 younger siblings, so we donÃ¢Â€Â™t have enough money to give my dad a proper resting place.\n",
        "\n",
        "thank you all so much, if u canÃ¢Â€Â™t donate just please share. thank you\n",
        "\n",
        "update: hello everyone, my dad has passed away on 10/29, thank you for all the support and love.\n",
        "WeÃ¢Â€Â™ve raised so much so far and iÃ¢Â€Â™m really grateful for every single dollar. thank you.\n",
        "we are now raising money to pay for his cremation and other funds for him. i was thinking of buying jewelry with his ashes inside so we can always have him around.\n",
        "with this money we can make that possible because of all your help. thank you so much.```\n",
        "\n",
        "Tasks and Steps: The above is a story from GoFundMe. Your task is to write a new\n",
        "version of the text that conveys the emotion {emotion}. You need to follow the\n",
        "steps below. Let's think step by step.\n",
        "Step 1: Describe the content and main events of the story.\n",
        "Step 2: Think about what emotions conveyed in the current story.\n",
        "Step 3: Think about how you rewrite the same story but convey emotion {emotion}\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geGcBex1Dwyf",
        "outputId": "5e7ae3d1-871f-47df-ea50-69662a1e9adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: The story is about a person reaching out for help to raise funds for their father's cremation. The father is on his death bed, and the family is struggling financially to give him a proper resting place. Despite the difficult circumstances, the person is grateful for the support they have received.\n",
            "\n",
            "Step 2: The current story conveys emotions of desperation, hope, gratitude, and love. The person is desperate for financial help, hopeful that they can raise enough funds, grateful for the support they have received, and expresses love for their father by wanting to keep his memory close through jewelry with his ashes.\n",
            "\n",
            "Step 3: Rewrite the story to convey sadness:\n",
            "\"Hello everyone, it pains me to write this message as I am in desperate need of help. My father recently passed away on 10/29, and we are struggling to afford his cremation. With my mom being the sole provider for me and my younger siblings, we are unable to give my father the proper farewell he deserves. The thought of not being able to provide him with a dignified resting place fills me with overwhelming sadness. Despite the heartache, I am grateful for the support and love we have received during this difficult time. We are now trying to raise funds for his cremation and other expenses, including a piece of jewelry to keep his memory close to our hearts. Your help in this time of sorrow would mean the world to us. Thank you for your kindness.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = \"anger\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "System: You are an expert in emotional psychology and you can accurately write\n",
        "stories with different emotions.\n",
        "\n",
        "Text: ```My wife Janice was recently diagnosed with Acute Promyelocytic Leukemia and will need to stay in the hospital for an extended period of time, for at least a month.\n",
        "While we are grateful that the outlook for her cure is positive at the moment, we will run into some financial shortages during this difficult time (e.g. ambulance and hospital expenses, mortgage, child care for our two daughters, other family expenses, etc.).\n",
        "Hopefully with this GoFundMe campaign, we would be able to raise some money to support our financial needs during this time. We are hopeful that Yeshua has His plan for us.\n",
        "We strongly believe that the most powerful treatment is praying to Yeshua.```\n",
        "\n",
        "Tasks and Steps: The above is a story from GoFundMe. Your task is to write a new\n",
        "version of the text that conveys the emotion {emotion}. You need to follow the\n",
        "steps below. Let's think step by step.\n",
        "Step 1: Describe the content and main events of the story.\n",
        "Step 2: Think about what emotions conveyed in the current story.\n",
        "Step 3: Think about how you rewrite the same story but convey emotion {emotion}\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YNdAhNWDxCI",
        "outputId": "537061aa-b04a-4b6f-d105-804befecb066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: The story is about a man whose wife has been diagnosed with Acute Promyelocytic Leukemia and needs to stay in the hospital for an extended period of time. The couple is facing financial difficulties due to medical expenses and other family needs.\n",
            "\n",
            "Step 2: The current story conveys emotions of sadness, worry, and hope. The man is grateful for the positive outlook for his wife's cure but is concerned about the financial strain the situation is putting on their family. There is a sense of hope and reliance on faith to get through this difficult time.\n",
            "\n",
            "Step 3: Rewrite the story to convey anger:\n",
            "\"My wife Janice was recently diagnosed with Acute Promyelocytic Leukemia, and now we're stuck dealing with the financial burden of her hospital stay. The expenses keep piling up - ambulance costs, hospital bills, mortgage payments, childcare for our daughters - it's all too much to handle. We shouldn't have to rely on a GoFundMe campaign to get by. It's infuriating that we're in this situation, and I can't help but feel angry at the unfairness of it all. We're supposed to believe that praying to Yeshua is the answer, but right now, all I feel is anger at the hand we've been dealt.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II Fine-tuning"
      ],
      "metadata": {
        "id": "5tS-rk_0htP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we will explore how to fine-tune a LLM using OpenAI API for the text rewritten task.\n"
      ],
      "metadata": {
        "id": "qhiqrefnhyzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creation of fine-tuning data set"
      ],
      "metadata": {
        "id": "krMUN1bXEHMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fine-tune an LLM, we will need to create a fine-tuning data set. There are multiple approaches to creating such a data set.\n"
      ],
      "metadata": {
        "id": "PUpNO9GxEXY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the steps how I created the fine-tuning dataset\n",
        "\n",
        "**Data Preperation**\n",
        "\n",
        "I followed the following steps for preparing the dataset:\n",
        "\n",
        "1. **Data Loading:**\n",
        "\n",
        "The gofundme_sample.csv file is loaded into a pandas DataFrame. This file likely contains columns for messages and their associated emotions.\n",
        "\n",
        "2. **Data Splitting:**\n",
        "\n",
        "* The dataset is split into training and validation subsets using train_test_split from the sklearn.model_selection module. This helps in validating the model's performance on unseen data. The test size is set to 20% of the total data, and random_state=42 ensures reproducibility of the split.\n",
        "\n",
        "3. **Saving Split Data:**\n",
        "\n",
        "* The training and validation data are saved into new CSV files (goFund_train_data.csv and goFund_val_data.csv respectively), making them accessible for further processing without altering the original dataset.\n",
        "\n",
        "4. **Conversion to JSONL:**\n",
        "* A function convert_to_jsonl is defined to convert the CSV files into JSONL format, which is required for fine-tuning the OpenAI model. This function:\n",
        " * Reads the CSV file.\n",
        " * Iterates over each row to construct a prompt that includes the original message and its emotion, directing the model to rewrite the message to convey a target emotion (specified as \"calm\" by default).\n",
        " *  For simplicity and demonstration, the original message is echoed back as the completion. In a practical scenario, you would replace this with a text that has been rewritten to reflect the target emotion.\n",
        " * Writes each prompt-completion pair as a JSON object to a JSONL file.\n",
        "\n",
        "5. **Execution:**\n",
        "\n",
        "* The convert_to_jsonl function is executed twice: once for the training data and once for the validation data. This results in two JSONL files (goFund_train_data.jsonl and goFund_val_data.jsonl) that are ready to be used for fine-tuning.\n",
        "\n",
        "6. **Confirmation:**\n",
        "* Prints confirmation messages after saving the split data and after completing the conversion to JSONL format, providing clear feedback on the progress of the data preparation steps.\n",
        "\n",
        "**Final Observations**\n",
        "\n",
        "Post fine-tuning theLLM we saw that it is able to demonstrate an improved ability to recognize complex emotions in addition to the target emotion.\n",
        "\n",
        "For e.g.\n",
        "\n",
        "  * **Original Text:** Well, another seizure decided to sneak up on me and hit me with its best shot! Again, I do not have any recollection of this incident.\n",
        "I was told that I was blue when they found me, gray and arm was cold as I lay on the gurney! I had to be resuscitated twice and a 3rd time in the ICU! My brain had swelling so I had to be iced up like a keg cooler! They didn't know if I was going to come out of it, and if I did, what kind of condition would I be in? Brain dead? Vegetable? Could understand but mobility all screwed up? I scared the hell put of my poor family who drove in from everywhere to be by my side until I got through this! They are absolutely amazing and I have to give a HUGE shout out to the fucking rock of our family, the most selfish, positive, unbelievably head strong woman to walk this 3rd rock.... MOM! You never get enough thanks! We'd all be lost without you and that's no joke!\n",
        "\n",
        "* **Target Emotion:** Love\n",
        "\n",
        "* **Resulting Text:** Love enveloped me in its warm embrace as another seizure tried to take me down. In the midst of darkness, I was surrounded by the unwavering love of my family. Their presence, their strength, their unwavering support carried me through the toughest of times. My mother, the rock of our family, stood by my side, her love shining brighter than any fear or doubt. Her selflessness, her positivity, her resilience, all a testament to the power of a mother's love. I am forever grateful for her, for without her, I would be lost in a sea of uncertainty. Thank you, Mom, for being my guiding light, my source of love and strength.\n",
        "\n",
        "* **Text Emotions Recognization(Post Fine-Tune):** The emotion of this passage is gratitude and love."
      ],
      "metadata": {
        "id": "h_5N3ByNFabL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning and evaluation"
      ],
      "metadata": {
        "id": "nQyen7ysE5mZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Followed the OpenAI tutorial on fine-tuning to fine-tune GPT-3.5-turbo on your fine-tuning data set.\n",
        "\n",
        "After fine-tuning, tried the same prompts developed in Part I on the newly fine-tuned model and comment on its performance and your observation.\n"
      ],
      "metadata": {
        "id": "enG4ADZaqbvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes for the fine-tuning process                         #                                                              #\n",
        "################################################################################\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import openai\n"
      ],
      "metadata": {
        "id": "WppqV6v_qbHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Dataset"
      ],
      "metadata": {
        "id": "QoZucWGFREgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Modern_AI')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke6hvHZ6UsxF",
        "outputId": "d010b0ab-cf85-4c70-963e-9d95b7a0a152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilkW9N7TuPSP",
        "outputId": "5e4f19f3-40b4-4d89-94dc-01eb8f9ab26c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['flickr_all_256_256.zip',\n",
              " 'consumer_beverage.zip',\n",
              " 'flickr_data_labels.csv',\n",
              " 'beverage_consumer.csv',\n",
              " 'beverage_survey_instagram.csv',\n",
              " 'dogs-vs-cats-small.zip',\n",
              " 'tweets.train.tsv',\n",
              " 'tweets.test.tsv',\n",
              " 'gofundme_sample.csv',\n",
              " 'gofundme_development_set.csv',\n",
              " 'goFund_train_data.csv',\n",
              " 'goFund_val_data.csv',\n",
              " 'gofundme_sample.jsonl',\n",
              " 'goFund_train_data.jsonl']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('gofundme_sample.csv')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the training and validation data to new CSV files\n",
        "train_data.to_csv('goFund_train_data.csv', index=False)\n",
        "val_data.to_csv('goFund_val_data.csv', index=False)\n",
        "\n",
        "print(\"Training and validation data have been saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjCe-r_4Yvd3",
        "outputId": "ba84c68b-87cb-4fe5-8124-f77ade596123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and validation data have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_jsonl(csv_file, jsonl_file, target_emotion=\"calm\"):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    with open(jsonl_file, 'w') as f:\n",
        "        for _, row in df.iterrows():\n",
        "            # Construct the prompt to include the original message and its emotion\n",
        "            prompt = f\"Rewrite the following pitch from {row['emotion']} to {target_emotion}:\\n{row['message']}\\n###\"\n",
        "            # For the sake of the example, we'll just echo the message as the completion.\n",
        "            # In practice, you'd replace this with the actual modified text.\n",
        "            completion = row['message'] + \" <|endoftext|>\"\n",
        "            record = {\"prompt\": prompt, \"completion\": completion}\n",
        "            json.dump(record, f)\n",
        "            f.write('\\n')\n",
        "\n",
        "# Training\n",
        "csv_file_path = 'goFund_train_data.csv'\n",
        "jsonl_file_path = 'goFund_train_data.jsonl'\n",
        "convert_to_jsonl(csv_file_path, jsonl_file_path)\n",
        "\n",
        "# Validation\n",
        "csv_file_path = 'goFund_val_data.csv'\n",
        "jsonl_file_path = 'goFund_val_data.jsonl'\n",
        "convert_to_jsonl(csv_file_path, jsonl_file_path)\n",
        "\n",
        "print(\"Conversion to JSONL completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljf84gc_cPlK",
        "outputId": "6a62e2cb-b402-4f88-cc69-7a3a1e000c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion to JSONL completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading the Dataset"
      ],
      "metadata": {
        "id": "vrAp92TRRHsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# api_key =\n",
        "\n",
        "# Upload your file to OpenAI's servers and get the file ID\n",
        "file_path = 'goFund_train_data.jsonl'\n",
        "\n",
        "def upload_file(file_path):\n",
        "    url = 'https://api.openai.com/v1/files'\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {api_key}'\n",
        "    }\n",
        "    data = {\n",
        "        'purpose': 'fine-tune'\n",
        "    }\n",
        "    with open(file_path, 'rb') as f:\n",
        "        response = requests.post(url, headers=headers, data = data, files={'file': (file_path, f)})\n",
        "    return response.json()\n",
        "\n",
        "# Uploading file and starting fine-tune\n",
        "file_response = upload_file(file_path)\n",
        "file_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpuLKHVwqFwo",
        "outputId": "e7c3409e-6f29-497a-faa8-20186122d6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'object': 'file',\n",
              " 'id': 'file-Yue5dJCmzEb6emFnJwAMn9yB',\n",
              " 'purpose': 'fine-tune',\n",
              " 'filename': 'goFund_train_data.jsonl',\n",
              " 'bytes': 649046,\n",
              " 'created_at': 1714317830,\n",
              " 'status': 'processed',\n",
              " 'status_details': None}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional Validation File\n",
        "file_path = 'goFund_val_data.jsonl'\n",
        "\n",
        "file_response = upload_file(file_path)\n",
        "file_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqRYo9h4wxNr",
        "outputId": "712bcc15-0c3b-44ac-dabe-4341ffaa8cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'object': 'file',\n",
              " 'id': 'file-SMCZ1qrxfy9jT94xKyjAPDtW',\n",
              " 'purpose': 'fine-tune',\n",
              " 'filename': 'goFund_val_data.jsonl',\n",
              " 'bytes': 307559,\n",
              " 'created_at': 1714318830,\n",
              " 'status': 'processed',\n",
              " 'status_details': None}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Job"
      ],
      "metadata": {
        "id": "dYR7RU-CRSaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-Yue5dJCmzEb6emFnJwAMn9yB\",\n",
        "  validation_file='file-SMCZ1qrxfy9jT94xKyjAPDtW',\n",
        "  model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KYopsEdbmO4",
        "outputId": "37df915c-9993-46ed-bfab-fcb86fe8e884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-knrobPPJMrpqmHH6132vec0k', created_at=1714320041, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=712418011, status='validating_files', trained_tokens=None, training_file='file-Yue5dJCmzEb6emFnJwAMn9yB', validation_file='file-SMCZ1qrxfy9jT94xKyjAPDtW', integrations=[], user_provided_suffix=None, estimated_finish=None)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-7baXAHqNdqyXZjOrS8KleWIR\",\n",
        "  validation_file='file-SMCZ1qrxfy9jT94xKyjAPDtW',\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  hyperparameters={\n",
        "    \"n_epochs\": 15,\n",
        "\t\"batch_size\": 32,\n",
        "\t\"learning_rate_multiplier\": 0.1\n",
        "  }\n",
        ")\n",
        "job_id = response.id\n",
        "status = response.status\n",
        "\n",
        "print(f'Fine-tunning model with jobID: {job_id}.')\n",
        "print(f\"Training Response: {response}\")\n",
        "print(f\"Training Status: {status}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7zg4dImUC_P",
        "outputId": "7a6e4982-315f-453b-be4a-8ba1fbac4a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tunning model with jobID: ftjob-20MDkvkT5VYb5u0VHaE0ZjCw.\n",
            "Training Response: FineTuningJob(id='ftjob-20MDkvkT5VYb5u0VHaE0ZjCw', created_at=1714320108, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=32, learning_rate_multiplier=0.1), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=1611691271, status='validating_files', trained_tokens=None, training_file='file-7baXAHqNdqyXZjOrS8KleWIR', validation_file='file-SMCZ1qrxfy9jT94xKyjAPDtW', integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "Training Status: validating_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in client.fine_tuning.jobs.list(limit=1):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7OFf91zUJv3",
        "outputId": "2a383c32-a543-4bb2-edfd-b0c492ef8429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FineTuningJob(id='ftjob-20MDkvkT5VYb5u0VHaE0ZjCw', created_at=1714320108, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-7baXAHqNdqyXZjOrS8KleWIR is in the prompt-completion format, but the specified model gpt-3.5-turbo-0125 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=32, learning_rate_multiplier=0.1), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=1611691271, status='failed', trained_tokens=None, training_file='file-7baXAHqNdqyXZjOrS8KleWIR', validation_file='file-SMCZ1qrxfy9jT94xKyjAPDtW', integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-knrobPPJMrpqmHH6132vec0k', created_at=1714320041, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-Yue5dJCmzEb6emFnJwAMn9yB is in the prompt-completion format, but the specified model gpt-3.5-turbo-0125 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=712418011, status='failed', trained_tokens=None, training_file='file-Yue5dJCmzEb6emFnJwAMn9yB', validation_file='file-SMCZ1qrxfy9jT94xKyjAPDtW', integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-N37wnY2aZ0oWviPNWeiVcsLO', created_at=1714317979, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-7baXAHqNdqyXZjOrS8KleWIR is in the prompt-completion format, but the specified model gpt-3.5-turbo-0125 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=32, learning_rate_multiplier=0.1), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=1223326283, status='failed', trained_tokens=None, training_file='file-7baXAHqNdqyXZjOrS8KleWIR', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-rarhJwoqi1xbXSLakgTUbJdO', created_at=1714317935, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-7baXAHqNdqyXZjOrS8KleWIR is in the prompt-completion format, but the specified model gpt-3.5-turbo-0125 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=719320843, status='failed', trained_tokens=None, training_file='file-7baXAHqNdqyXZjOrS8KleWIR', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-x7QD9iwox9qmrA3NHAMECrAm', created_at=1714293387, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:hw3-rev4:9IvtfH02', finished_at=1714299486, hyperparameters=Hyperparameters(n_epochs=1, batch_size=28, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-DuTnJuYxBfIj5kEQkoEbBLcd'], seed=287749253, status='succeeded', trained_tokens=1180506, training_file='file-i3Yir2mIkwQT1LRzZolztRKn', validation_file='file-QkWlOcZzgmALXNuY6w1xVwJ2', integrations=[], user_provided_suffix='HW3_rev4', estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-j2gihZ3Wk1B2rAkYvpX62hDB', created_at=1714290026, error=Error(code='invalid_n_examples', message='Training file has 2 example(s), but must have at least 10 examples', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=1406165434, status='failed', trained_tokens=None, training_file='file-QNTBUOpGLIfEoKHNYszxUNkp', validation_file='file-nDtapqdtasEEMuOa0CBd1oVQ', integrations=[], user_provided_suffix='HW3_rev3', estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-bNBUbPv3YIvlC3xE3P9KpBst', created_at=1714285156, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Unexpected file format, expected either prompt/completion pairs or chat messages.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=1569909899, status='failed', trained_tokens=None, training_file='file-YcYR0wyOtogRiudJxUgKgbww', validation_file='file-agoUzHhLXZQb4GA9mV2sW2Po', integrations=[], user_provided_suffix='HW3_Finetune2', estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-mP4L32i8HnfJFLeYWxSykhDt', created_at=1714283577, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 1 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=915896037, status='failed', trained_tokens=None, training_file='file-chO4y9JSEqAI2iC7KuVXoGYq', validation_file='file-kYjeHKzI1w5ca9bUMY0WrErp', integrations=[], user_provided_suffix='HW3_Finetuning', estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-0g8dpFyVZ2UfeT89tOjx4b9F', created_at=1714257115, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9IkvFJkJ', finished_at=1714257300, hyperparameters=Hyperparameters(n_epochs=15, batch_size=32, learning_rate_multiplier=0.1), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-mOzUVNDVQZucCduDT7hXVeuY'], seed=1479164880, status='succeeded', trained_tokens=74730, training_file='file-TpvJ9aaLfMEVjHZWz46WzvfY', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-3DR4NTKbMKRhecNFlOc6j0wX', created_at=1714256974, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9Il2bPmL', finished_at=1714257755, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-AAhibMsKGzu4X6TT0ooZCJkU'], seed=15323645, status='succeeded', trained_tokens=14946, training_file='file-TpvJ9aaLfMEVjHZWz46WzvfY', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-iqsudwAdbomHvlTO1b0jfs83', created_at=1714255426, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9IkTohKm', finished_at=1714255599, hyperparameters=Hyperparameters(n_epochs=15, batch_size=32, learning_rate_multiplier=0.1), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-xcZBkrZcmSO4m2JLKXiicOV4'], seed=420972385, status='succeeded', trained_tokens=69525, training_file='file-O1xhxPIO8FWXP0nMfZqLjikN', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-iYzMq1cT4iZtdVya3ItVAfpc', created_at=1714255424, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9IkZg2Z6', finished_at=1714255963, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-oG2aQhQ1dz04qokFHJzB7u7k'], seed=32774333, status='succeeded', trained_tokens=14946, training_file='file-lEhQnRhMnqA3JJmSn2X3CVhe', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-Mxb5lGX6b5bjnAtjRlHuDVIZ', created_at=1714254064, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9Ik7s2hR', finished_at=1714254238, hyperparameters=Hyperparameters(n_epochs=15, batch_size=32, learning_rate_multiplier=0.1), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-dzuG3SSwsPsGNP3iBTiCQVLj'], seed=1376215560, status='succeeded', trained_tokens=69525, training_file='file-O1xhxPIO8FWXP0nMfZqLjikN', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-73e1WRedoXEqZb7acIwtmO3U', created_at=1714253940, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9IkCHvQg', finished_at=1714254512, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-BiS4SNuzoFQ1vHcDMXDvyyjG'], seed=2089218272, status='succeeded', trained_tokens=14946, training_file='file-lEhQnRhMnqA3JJmSn2X3CVhe', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-sEdgwmVBdaPwvCUnvHLoruWA', created_at=1714203206, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 1 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=1226981594, status='failed', trained_tokens=None, training_file='file-xzesIYUDOLOPBGpZPwlnBlF3', validation_file='file-gOmgqarc5KZxLRyXnltRweSu', integrations=[], user_provided_suffix='HW3_Finetuning', estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-RJISPTriMXWb1DlbwLd6H9dl', created_at=1714176835, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9IQJslAM', finished_at=1714178102, hyperparameters=Hyperparameters(n_epochs=15, batch_size=3, learning_rate_multiplier=0.3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-RXkgDBsDX38u8bWKw7xySLFR'], seed=601750536, status='succeeded', trained_tokens=69525, training_file='file-O1xhxPIO8FWXP0nMfZqLjikN', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-EHvTJSyZugDBAabaF8bAxq2e', created_at=1714175414, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=276103800, status='cancelled', trained_tokens=None, training_file='file-O1xhxPIO8FWXP0nMfZqLjikN', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-3WmfYAoMz2RNBtN9mWx3QUa4', created_at=1713903866, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=1423824523, status='cancelled', trained_tokens=None, training_file='file-bBI5VeSHWCh0KeTdnPs68Abo', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=1714320351)\n",
            "FineTuningJob(id='ftjob-hSZPGboF85EHMJlQoLbwPL23', created_at=1713891226, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9HDqjuMb', finished_at=1713891840, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-eZGchLhzX6udurnvqcVNYUPw'], seed=1673481916, status='succeeded', trained_tokens=129444, training_file='file-Ciz8WVJehs4NooYEl0pTrg3y', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-pSQ1lraiI2y1yNIHHh3Xt1LD', created_at=1713890856, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9HDkwG2k', finished_at=1713891480, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-m0EYdt8wJwZfWwZwCR3IoIqe'], seed=1462639287, status='succeeded', trained_tokens=126144, training_file='file-DYnezlUxxM9ITUOwaBJoejfd', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-MsdgkjWI1AXTeB2jLtf11wEP', created_at=1713890602, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9HDgL3IB', finished_at=1713891195, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-SFpct5SKDiC9J7mCw8CcnPBR'], seed=235899910, status='succeeded', trained_tokens=126144, training_file='file-jZupHGZBrZyazXTSNrxkj7Nf', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-veVlt59H9pDX3vNACr0PRDsT', created_at=1713890146, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9HDcgxt9', finished_at=1713890968, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=['file-CGNzJYBum7rUscdzM0DhmesI'], seed=1044834123, status='succeeded', trained_tokens=126144, training_file='file-jZupHGZBrZyazXTSNrxkj7Nf', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-snD3ITFi6unjnD1AIi1lYqV6', created_at=1713806676, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=517204264, status='cancelled', trained_tokens=None, training_file='file-JQppOg5Oy4iyLh9NibPlRrhJ', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-2rlx3QQ8WlDQSpxeQKMJHMlh', created_at=1713806653, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=1089359924, status='cancelled', trained_tokens=None, training_file='file-UNQZ2CHJMaoxSyJQsUDtF4qg', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-1uUAvQ7CCGrUDa3auGVEwVWx', created_at=1713806223, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=859309761, status='cancelled', trained_tokens=None, training_file='file-UNQZ2CHJMaoxSyJQsUDtF4qg', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-AUlFzx5R9fEf5vMYMIm4FKAz', created_at=1713772622, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=676266857, status='cancelled', trained_tokens=None, training_file='file-UNQZ2CHJMaoxSyJQsUDtF4qg', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n",
            "FineTuningJob(id='ftjob-6lI87itgVupZvLWerICdA1IH', created_at=1713770157, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-dStTSLOVLNSFy6iYbaKpbade', result_files=[], seed=426465281, status='cancelled', trained_tokens=None, training_file='file-bBI5VeSHWCh0KeTdnPs68Abo', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuned Model Evaluation"
      ],
      "metadata": {
        "id": "Q4SU_VbiRacA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0125:personal::9IkvFJkJ\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"```Listen up! My name is Debbi and I'm here to raise funds for my brother Donald Webb. Let me tell you something that will make your blood boil - he's only 51 years old and back in 2016, he was hit with a barrage of strokes that robbed him of his motor skills and memories. And if that wasn't enough, now his kidneys are failing and he's on the fast track to dialysis. As if that's not infuriating already, he's also battling high blood pressure and diabetes. He's stuck in the hospital for who knows how long, and every single day there costs a whopping $450 just to keep his bed at The Regency at Shelby in Shelby Township Mi, his care facility. We need all the help we can get to ensure he gets the care he deserves.```\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the emotion of this sentence \"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiwaoE6sUTlK",
        "outputId": "3e4cc83e-38b4-480a-b19b-273b718e547c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The emotion conveyed in this passage is a mix of sadness, frustration, and urgency. It highlights the immense challenges faced by Donald Webb and the urgency of raising funds to support his healthcare needs.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0125:personal::9IkvFJkJ\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"```Love enveloped me in its warm embrace as another seizure tried to take me down. In the midst of darkness, I was surrounded by the unwavering love of my family. Their presence, their strength, their unwavering support carried me through the toughest of times. My mother, the rock of our family, stood by my side, her love shining brighter than any fear or doubt. Her selflessness, her positivity, her resilience, all a testament to the power of a mother's love. I am forever grateful for her, for without her, I would be lost in a sea of uncertainty. Thank you, Mom, for being my guiding light, my source of love and strength.```\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the emotion of this sentence \"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAfbSy2BU57B",
        "outputId": "d4c360a3-e378-4d0e-e0fd-cec39cdd5d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The emotion of this passage is gratitude and love.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0125:personal::9IkvFJkJ\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Out of nowhere, my blood pressure surged on Friday, sending me rushing to the ER. After being transferred to Dallas, I received a terrifying diagnosis of severe preeclampsia. I'm facing a long stay until Greyson arrives, possibly as early as 34 weeks. Not only will he be born prematurely, but he also has a heart defect requiring surgery. This unexpected turn has left us reeling, with 3 kids at home needing care and bills piling up. Joseph is juggling meals and trips between Dallas and Tyler. Any support during this frightening time would mean the world to us as we confront these daunting challenges.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the emotion of this sentence \"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07PnwzjzVh4w",
        "outputId": "4170df89-e072-4a3e-eba8-ecbf6a0ea94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The emotion conveyed in this message is one of fear, uncertainty, and vulnerability. The unexpected and serious diagnosis of severe preeclampsia, the premature birth of the baby, and the additional complication of a heart defect requiring surgery have left the family reeling and facing daunting challenges. The mention of bills piling up and the struggle of juggling care for three children at home while also being in the hospital adds to the sense of stress and overwhelm. Overall, the tone is one of needing support and facing a difficult and frightening situation.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0125:personal::9IkvFJkJ\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Hello everyone. I am overwhelmed with gratitude for the love and support I have received during this challenging time. For the past 20 months, I have been facing mysterious medical issues that have led to numerous tests, procedures, and medications. While my health insurance has been helpful, the bills are starting to add up. I am humbly reaching out to ask for your help, not out of desperation, but out of love and appreciation for the community that surrounds me. Your generosity, no matter how big or small, will mean the world to me. Thank you for being a beacon of love and light in my life.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the emotion of this sentence \"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_5MNqiPVy0n",
        "outputId": "06d8f152-cb0f-4ec3-baf9-4f7aec94028b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The emotion conveyed in the sentence is gratitude.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0125:personal::9IkvFJkJ\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Hello everyone, it pains me to write this message as I am in desperate need of help. My father recently passed away on 10/29, and we are struggling to afford his cremation. With my mom being the sole provider for me and my younger siblings, we are unable to give my father the proper farewell he deserves. The thought of not being able to provide him with a dignified resting place fills me with overwhelming sadness. Despite the heartache, I am grateful for the support and love we have received during this difficult time. We are now trying to raise funds for his cremation and other expenses, including a piece of jewelry to keep his memory close to our hearts. Your help in this time of sorrow would mean the world to us. Thank you for your kindness.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the emotion of this sentence \"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRDbR4IrVzHA",
        "outputId": "8832dd94-c7e7-4424-bbbf-90b39a2dfa3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The emotion conveyed in the message is sadness and desperation.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0125:personal::9IkvFJkJ\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"My wife Janice was recently diagnosed with Acute Promyelocytic Leukemia, and now we're stuck dealing with the financial burden of her hospital stay. The expenses keep piling up - ambulance costs, hospital bills, mortgage payments, childcare for our daughters - it's all too much to handle. We shouldn't have to rely on a GoFundMe campaign to get by. It's infuriating that we're in this situation, and I can't help but feel angry at the unfairness of it all. We're supposed to believe that praying to Yeshua is the answer, but right now, all I feel is anger at the hand we've been dealt.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What's the emotion of this sentence \"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSjS4KLyVzZt",
        "outputId": "6e802f12-8bed-4e7f-d1cc-cc0aaded1fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"The primary emotion conveyed in this passage is anger. The speaker expresses frustration and resentment at the financial burden and hardships they are facing due to their wife's illness.\", role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "\n",
        "The above is developed based on materials from [1], [2], [3], and [4]\n",
        "\n"
      ],
      "metadata": {
        "id": "0HofNHqgFC5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] “LLMs and Marketing Narratives” (work in progress), Samsun Knight and Liu Liu\n",
        "\n",
        "[2] https://stanford-cs324.github.io/winter2022/projects/CS324_P1.pdf\n",
        "\n",
        "[3] Li, Zaijing, Gongwei Chen, Rui Shao, Dongmei Jiang, and Liqiang Nie. \"Enhancing the Emotional Generation Capability of Large Language Models via Emotional Chain-of-Thought.\" arXiv preprint arXiv:2401.06836 (2024).\n",
        "\n",
        "[4] Shu, Lei, Liangchen Luo, Jayakumar Hoskere, Yun Zhu, Yinxiao Liu, Simon Tong, Jindong Chen, and Lei Meng. \"Rewritelm: An instruction-tuned large language model for text rewriting.\" In Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 17, pp. 18970-18980. 2024.\n"
      ],
      "metadata": {
        "id": "tkD9Bc1dFLcH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHUpQ-HhFKnC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}